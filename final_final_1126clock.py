# final_stable_recorder.py (Âü∫‰∫é weqeqwe.py ÊàêÂäüÊû∂ÊûÑÔºåÂåÖÂê´ÂêØÂä®ÂêåÊ≠•ÁöÑÊúÄÁªàÂÆåÊï¥Áâà)

import cv2
import os
import sys
import numpy as np
import torch
import yaml  # ËÆÄÂèñ YAML ÈÖçÁΩÆÊ™î
from aiortc import RTCSessionDescription, RTCPeerConnection # aiortcÊòØ WebRTC ÁöÑ Python ÂØ¶‰Ωú
#RTCPeerConnection Áî®ÊñºÂª∫Á´ã WebRTC ÈÄ£Á∑ö

from ultralytics import YOLO # YOLOv8 Áâ©‰ª∂ÂÅµÊ∏¨Ê®°Âûã
from boxmot.trackers.bytetrack.bytetrack import ByteTrack # ByteTrack ËøΩËπ§Âô®
from collections import defaultdict, deque # Áî®ÊñºÂÑ≤Â≠òËøΩËπ§Ê≠∑Âè≤

import time
import uuid# Áî®ÊñºÁî¢ÁîüÂîØ‰∏ÄÁöÑË°åÁ®ã ID
import requests # Áî®ÊñºËàá Flask ÂæåÁ´ØÈÄöË®ä

#asyncio Ëàá aiohttp Áî®ÊñºÈùûÂêåÊ≠• WebRTC ÂΩ±ÂÉèÊé•Êî∂
#Âõ†ÁÇ∫ WebRTC ÈúÄË¶ÅÈùûÂêåÊ≠•ËôïÁêÜ‰æÜÊúâÊïàÁéáÂú∞Êé•Êî∂ÂΩ±ÂÉè‰∏≤ÊµÅ


#webrtc ‰ªñÁöÑËôïÁêÜÊ≠•È©üÂåÖÂê´ 1.Âª∫Á´ã RTCPeerConnection 2.‰∫§Êèõ SDP 3.Êé•Êî∂ÂΩ±ÂÉè Track
#asynicio ‰∏ªË¶ÅËôïÁêÜÁöÑÈÉ®ÂàÜÊòØÁ≠âÂæÖÂΩ±ÂÉèÂπÄÁöÑÊé•Êî∂
#http   ÂâáÊòØÁî®‰æÜËàá mediamtx ‰º∫ÊúçÂô®‰∫§Êèõ SDP
import asyncio # ÈùûÂêåÊ≠•ËôïÁêÜ
import aiohttp # ÈùûÂêåÊ≠• HTTP Ë´ãÊ±Ç
from aiortc import RTCConfiguration, RTCIceServer  #ÈÄôÈÇäÂâáÊòØÁî®‰æÜË®≠ÂÆö ICE ‰º∫ÊúçÂô®
# ÁîöÈ∫ºÊòØICE ‰º∫ÊúçÂô®Âë¢? ICE ‰º∫ÊúçÂô®Áî®ÊñºÂçîÂä© WebRTC ÈÄ£Á∑öÁöÑÂª∫Á´ã
#Áõ∏Áï∂Êñº‰∏≠‰ªã‰º∫ÊúçÂô® Âπ´Âä©ÈõôÊñπÊâæÂà∞ÂΩºÊ≠§ ÈÄôË£°ÁöÑÈõôÊñπ ÊòØÊåáÂÖ©ÂÄã WebRTC ÂÆ¢Êà∂Á´Ø ‰∏ÄÂÄãpc ‰∏ÄÂÄãmeadiamtx
#configuraion ÊòØÁî®‰æÜË®≠ÂÆö RTCPeerConnection ÁöÑÂèÉÊï∏
#ÊàëÂÄëÂú®ÈÄôË£°Ë®≠ÂÆö ICE ‰º∫ÊúçÂô® ËÆì WebRTC ËÉΩÂ§†È†ÜÂà©Á©øË∂ä NAT ËàáÈò≤ÁÅ´ÁâÜ
#ÈÄôÊ®£ÊâçËÉΩÊàêÂäüÂª∫Á´ã P2P ÈÄ£Á∑ö
#rtcsessiondescription ÂâáÊòØÁî®‰æÜÂ∞ÅË£ù SDP Ë≥áË®äÁöÑÁâ©‰ª∂
#SDP ÊòØ WebRTC Áî®‰æÜÊèèËø∞Â§öÂ™íÈ´îÈÄ£Á∑öÂèÉÊï∏ÁöÑÊ†ºÂºè
#ÂÆÉÂåÖÂê´‰∫ÜÁ∑®Ëß£Á¢ºÂô® Á∂≤Ë∑Ø‰ΩçÂùÄÁ≠âË≥áË®ä




import traceback # Áî®ÊñºÈåØË™§ËøΩËπ§
import threading # Â§öÂü∑Ë°åÁ∑íËôïÁêÜ

from queue import Queue, Empty # Á∑öÁ®ãÂÆâÂÖ®ÁöÑ‰ΩáÂàó
#ÈÄôÂÄãÁ∑öÁ®ãÂ∞±ÊòØthreading.Thread ‰ªñËÉΩÂ§†ËÆìÊàëÂÄëÂú®ËÉåÊôØÂü∑Ë°å‰ªªÂãô
#Queue ÊòØÁ∑öÁ®ãÂÆâÂÖ®ÁöÑ‰ΩáÂàó Áî®ÊñºÂú®‰∏çÂêåÁ∑öÁ®ãÈñìÂÇ≥ÈÅûË≥áÊñô

import torch.nn.functional as F #pytorch ÁöÑÂáΩÂºèÂ∫´ Áî®ÊñºÂºµÈáèÊìç‰Ωú ÂºµÈáèÊòØÂ§öÁ∂≠Èô£Âàó È°û‰ºº numpy ÁöÑÈô£Âàó
from datetime import datetime # Áî®ÊñºÂèñÂæóÁõÆÂâçÊôÇÈñì


import time
# --- 1. Ë∑ØÂæÑ‰∏éÈÖçÁΩÆ ---


try:
    CURRENT_DIR = os.path.dirname(os.path.abspath(__file__)) #Áï∂ÂâçÊ™îÊ°àË∑ØÂæë
    PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, '..')) #Â∞àÊ°àÊ†πÁõÆÈåÑ #Â∞±ÊòØ‰∏ä‰∏ÄÂ±§ÁõÆÈåÑstream_yolo
    YNET_PROJECT_PATH = os.path.join(PROJECT_ROOT, 'Ynet_kitti_tracking-master') #Y-Net Â∞àÊ°àË∑ØÂæë #stream_yolo/Ynet_kitti_tracking-master
    if YNET_PROJECT_PATH not in sys.path: #Â¶ÇÊûú YNET_PROJECT_PATH ‰∏çÂú®Á≥ªÁµ±Ë∑ØÂæë‰∏≠
        sys.path.append(YNET_PROJECT_PATH) #Âä†ÂÖ•Á≥ªÁµ±Ë∑ØÂæë Á≥ªÁµ±Ë∑ØÂæë
    from model import YNet #Y-Net Ê®°Âûã
    from network import modeling #
    from utils.image_utils import create_arrow_heatmap, get_patch, create_dist_mat, sampling #Y-Net Â∑•ÂÖ∑ÂáΩÂºè
except ImportError as e:
    print(f"ÈîôËØØÔºöÊó†Ê≥ïÂØºÂÖ• Y-Net Áõ∏ÂÖ≥Ê®°ÁªÑ: {e}")
    print(f"ËØ∑Á°Æ‰øù 'Ynet_kitti_tracking-master' Êñá‰ª∂Â§π‰∏éÊÇ®ÁöÑ‰∏ìÊ°àÊñá‰ª∂Â§π‰Ωç‰∫éÂêå‰∏ÄÂ±ÇÁõÆÂΩï‰∏ã„ÄÇ")
    sys.exit(1)

# --- ÈÖçÁΩÆÈÅ∏È†Ö --- ÂèØÈÅ∏Êìá WebRTC Êàñ Êú¨Âú∞ Webcam ‰ΩúÁÇ∫Ëº∏ÂÖ•‰æÜÊ∫ê
INPUT_SOURCE_MODE = "WEBCAM"  # ÂèØÈÄâÈ°π: "WEBRTC" Êàñ "WEBCAM"

# --- ÈÄöÁî®ÈÖçÁΩÆ ---
VIDEO_FILES_DIR = "videos"  #ÂΩ±ÁâáÂÑ≤Â≠òÁõÆÈåÑ
RECORD_OUTPUT_DIR = os.path.join(CURRENT_DIR, "web_server", VIDEO_FILES_DIR) #Áï∂Ââç‰ΩçÁΩÆÁöÑ web_server/videos
os.makedirs(RECORD_OUTPUT_DIR, exist_ok=True) #Á¢∫‰øùÁõÆÈåÑÂ≠òÂú®
print(f"ÂΩ±ÁâáÂ∞ÜÂÇ®Â≠òËá≥: {RECORD_OUTPUT_DIR}") #ÂàóÂç∞ÂΩ±ÁâáÂÑ≤Â≠òÁõÆÈåÑ

FLASK_BACKEND_URL = "http://192.168.196.207:5000"  #Flask ÂæåÁ´Ø‰º∫ÊúçÂô® URL ÈÄôzerotierÁµ¶ÁöÑ ÊâÄ‰ª•Âè™Ë¶ÅÂú®Âêå‰∏ÄÂÄãÁ∂≤Ë∑ØÂ∞±ÂèØ‰ª•ÈÄ£Âà∞ androidÂè™Ë¶ÅzerotierÂ∞±ÂèØ‰ª•ÈÄ£Âà∞ÈÄôÂÄãip ÊäägpsÂÇ≥ÂõûÂéª
RECORDING_STATUS_ENDPOINT = f"{FLASK_BACKEND_URL}/recording_status"  #POST /recording_status
UPLOAD_VIDEO_ENDPOINT = f"{FLASK_BACKEND_URL}/upload_recorded_video" #POST /upload_recorded_video
NOTIFY_DANGER_ENDPOINT = f"{FLASK_BACKEND_URL}/notify_danger" #POST /notify_danger

YOLO_MODEL_PATH = os.path.join(YNET_PROJECT_PATH, 'yolov8m.pt') #YOLOv8 Ê®°ÂûãË∑ØÂæë
YNET_MODEL_PATH = os.path.join(YNET_PROJECT_PATH, 'pretrained_models/kitti_ynet_baseline_s8_best.pt') #Y-Net Ê®°ÂûãË∑ØÂæë
SEG_MODEL_PATH = os.path.join(YNET_PROJECT_PATH, 'segmentation_models/best_deeplabv3plus_mobilenet_cityscapes_os16.pth')#Ë™ûÁæ©ÂàÜÂâ≤Ê®°ÂûãË∑ØÂæë
YNET_CONFIG_PATH = os.path.join(YNET_PROJECT_PATH, r'kitti_train_data/config/kitti.yaml') #Y-Net ÈÖçÁΩÆÊ™îË∑ØÂæë

SEGMENTATION_INTERVAL = 2 #ÊØè N ÂπÄÂü∑Ë°å‰∏ÄÊ¨°Ë™ûÁæ©ÂàÜÂâ≤
MODEL_INPUT_WIDTH = 320 #YOLO Ëàá Y-Net Ê®°ÂûãËº∏ÂÖ•Â∞∫ÂØ∏
MODEL_INPUT_HEIGHT = 96 #YOLO Ëàá Y-Net Ê®°ÂûãËº∏ÂÖ•Â∞∫ÂØ∏
CLASSES_TO_TRACK = [0, 1, 2, 3, 5, 7] # Â¢ûÂä†‰∫Ü 0: person
SAVE_VIDEO = True #ÊòØÂê¶ÂÑ≤Â≠òÈåÑÂΩ±ÂΩ±Áâá

# --- WebRTC ÈÖçÁΩÆ ---
mediamtx_base_url = "http://192.168.196.73:8889" # ËøúÁ´ØÊ†ëËéìÊ¥æÁöÑ ZeroTier IP   #WIFI  10.21.78.41:8889
stream_paths = ["cam0", "cam1"]

# --- Êú¨Âú∞ Webcam ÈÖçÁΩÆ ---
local_camera_indices = [0] #Êú¨Âú∞ÊîùÂÉèÈ†≠

# ---ÂØ´ÂÖ•ÂΩ±ÁâáÁöÑÂü∑Ë°åÁ∑í---
class VideoWriterThread(threading.Thread): #ÂΩ±ÁâáÂØ´ÂÖ•Âü∑Ë°åÁ∑í
    def __init__(self, output_path, frame_size, fps=20.0):
        super().__init__() #ÂëºÂè´Áà∂È°ûÂà•threading.ThreadÁöÑÂàùÂßãÂåñÊñπÊ≥ï
        self.daemon = True #Ë®≠ÁΩÆÁÇ∫ÂÆàË≠∑Á∑öÁ®ã ‰ΩúÁî®ÊòØÁï∂‰∏ªÁ∑öÁ®ãÁµêÊùüÊôÇ Ëá™ÂãïÁµêÊùüÈÄôÂÄãÁ∑öÁ®ã ÈÄôÊ®£Â∞±‰∏çÁî®ÂØ´ .join() ‰æÜÁ≠âÂæÖÁ∑öÁ®ãÁµêÊùü
        self.output_path, self.frame_size, self.fps = output_path, frame_size, fps #ÂΩ±ÁâáËº∏Âá∫Ë∑ØÂæë ÂπÄÂ∞∫ÂØ∏ ÂπÄÁéá
        self.write_queue = Queue(maxsize=120) #ÂØ´ÂÖ•‰ΩáÂàó ÊúÄÂ§ö120ÂπÄ
        self.running = True #Âü∑Ë°åÁãÄÊÖã
        self.writer = None #ÂΩ±ÁâáÂØ´ÂÖ•Âô®
    def run(self): #ÁÇ∫‰ªÄÈ∫º‰∏ÄÂÆöË¶ÅË¶ÜÂØ´ run ÊñπÊ≥ï? Âõ†ÁÇ∫ threading.Thread ÁöÑ run ÊñπÊ≥ïÊòØÁ©∫ÁöÑ
        #threading.Thread Âú®Êñ∞Âü∑Ë°åÁ∑íÂÖßÂü∑Ë°åÁöÑ„ÄåÂÖ•Âè£ÂáΩÂºè„Äç„ÄÇË¶ÜÂØ´ run() ÁöÑÁõÆÁöÑÂ∞±ÊòØÊää‰Ω†Ë¶ÅÂú®ÈÇ£ÂÄãÊñ∞Âü∑Ë°åÁ∑íË£°ÂÅöÁöÑÂ∑•‰ΩúÂØ´ÈÄ≤Âéª
        try:
            fourcc = cv2.VideoWriter_fourcc(*'avc1') #‰ΩøÁî® AVC1 Á∑®Á¢ºÂô®
            self.writer = cv2.VideoWriter(self.output_path, fourcc, self.fps, self.frame_size)#Âª∫Á´ãÂΩ±ÁâáÂØ´ÂÖ•Âô®
            if not self.writer.isOpened(): raise IOError("AVC1 failed") #Ê™¢Êü•ÊòØÂê¶ÊàêÂäüÈñãÂïü
            print(f"ÂΩ±ÁâáÂØ´ÂÖ•Âü∑Ë°åÁ∑í(avc1)Â∑≤ÂïüÂãï: {os.path.basename(self.output_path)}")
        except Exception:
            print(f"Ë≠¶Âëä: AVC1 Á∑®Á¢ºÂô®‰∏çÂèØÁî®, ÈôçÁ¥öËá≥ MP4V for {os.path.basename(self.output_path)}")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            self.writer = cv2.VideoWriter(self.output_path, fourcc, self.fps, self.frame_size)#Âª∫Á´ãÂΩ±ÁâáÂØ´ÂÖ•Âô®
        while self.running or not self.write_queue.empty(): #ÊåÅÁ∫åÂØ´ÂÖ•Áõ¥Âà∞ÂÅúÊ≠¢‰∏î‰ΩáÂàóÊ∏ÖÁ©∫ ‰ΩáÂàóÊòØ
            try:
                frame = self.write_queue.get(timeout=1) #Á≠âÂæÖ1ÁßíÂèñÂá∫‰∏ÄÂπÄ
                if self.writer: self.writer.write(frame) #ÂØ´ÂÖ•ÂΩ±Áâá
            except Empty: continue
        if self.writer: self.writer.release() #ÈáãÊîæÂΩ±ÁâáÂØ´ÂÖ•Âô®
        print(f"ÂΩ±Áâá {os.path.basename(self.output_path)} ÂØ´ÂÖ•ÂÆåÊàê„ÄÇ")
    def add_frame_to_queue(self, frame): #Âä†ÂÖ•ÂπÄÂà∞‰ΩáÂàó
        if not self.write_queue.full(): self.write_queue.put_nowait(frame) #ÈùûÈòªÂ°ûÂä†ÂÖ•
    def stop(self): self.running = False#ÂÅúÊ≠¢ÂØ´ÂÖ•






def notify_backend(endpoint, data): #ÈÄöÁü• Flask ÂæåÁ´Ø
    try:
        response = requests.post(endpoint, json=data, timeout=5) #POST Ë´ãÊ±Ç
        response.raise_for_status() #Ê™¢Êü•ÊòØÂê¶ÊàêÂäü
        print(f"ÊàêÂäüÈÄöÁü•ÂæåÁ´Ø {os.path.basename(endpoint)}ÔºåÁãÄÊÖãÁ¢º: {response.status_code}") #ÂàóÂç∞ÊàêÂäüË®äÊÅØ
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"ÈåØË™§ÔºöÈÄöÁü•ÂæåÁ´Ø {os.path.basename(endpoint)} Â§±Êïó: {e}")
        return None






#Âª∫Á´ã RTCPeerConnection ‰∏¶‰∫§Êèõ SDP ÁÑ∂ÂæåÊé•Êî∂ÂΩ±ÂÉè Track
#Ë©¢Âïè: ÈÄôÈÇäÂà∞print(f"[{path}] WebRTC ÈÄ£Á∑öÂ∑≤ÈóúÈñâ„ÄÇ")  ÈÄôÊ®£ÈÇÑ‰∏çÂ§†Âóé?
#Á≠î: ÈÄôÊÆµÁ®ãÂºèÁ¢ºÁ¢∫ÂØ¶Ê∂µËìã‰∫ÜÂª∫Á´ã WebRTC ÈÄ£Á∑ö‰∏¶Êé•Êî∂ÂΩ±ÂÉèÁöÑÂü∫Êú¨ÊµÅÁ®ã
#‰∏çÈÅéÂú®ÂØ¶ÈöõÊáâÁî®‰∏≠ ÂèØËÉΩÈÇÑÈúÄË¶ÅËÄÉÊÖÆÊõ¥Â§öÁöÑÈåØË™§ËôïÁêÜ ËàáÈáçÈÄ£Ê©üÂà∂
#‰æãÂ¶ÇÂ¶ÇÊûúÈÄ£Á∑ö‰∏≠Êñ∑‰∫Ü ÊÄéÈ∫ºËá™ÂãïÈáçÈÄ£
#ÊàñËÄÖÂ¶ÇÊûúÊé•Êî∂ÂΩ±ÂÉèÂπÄË∂ÖÊôÇ‰∫Ü ÊÄéÈ∫ºËôïÁêÜ
#ÈÄô‰∫õÈÉΩÂèØ‰ª•Ê†πÊìöÂØ¶ÈöõÈúÄÊ±Ç‰æÜÊì¥Â±ïÈÄôÂÄãÂü∫Á§éÁöÑÊé•Êî∂‰ªªÂãô

async def webrtc_receiver_task(path, frame_queue, shutdown_event): #ÈùûÂêåÊ≠• WebRTC Êé•Êî∂‰ªªÂãô
    pc = RTCPeerConnection() #Âª∫Á´ã RTCPeerConnection


    @pc.on("track") #Áï∂Êé•Êî∂Âà∞ Track ÊôÇËß∏Áôº  ÈÄôË£°ÁöÑ Track Â∞±ÊòØÂΩ±ÂÉè‰∏≤ÊµÅ ÊàëÈÄôÈÇäÊé•Êî∂ mediamtx ‰º∫ÊúçÂô®ÂÇ≥‰æÜÁöÑÂΩ±ÂÉè‰∏≤ÊµÅ
    async def on_track(track): #Êé•Êî∂ Track ÁöÑÂõûÂëºÂáΩÂºè
        if track.kind == "video": #Â¶ÇÊûúÊòØÂΩ±ÂÉè Track
            while not shutdown_event.is_set(): #ÊåÅÁ∫åÊé•Êî∂Áõ¥Âà∞ÈóúÈñâ‰∫ã‰ª∂Ë¢´Ë®≠ÂÆö #shutdown_event ÊòØ threading.Event Áî®ÊñºÈÄöÁü•ÈóúÈñâ
                try:
                    frame = await asyncio.wait_for(track.recv(), timeout=10) # ÈÄôË£°ÁöÑ track.recv() ÊòØÈùûÂêåÊ≠•ÊñπÊ≥ï Áî®ÊñºÊé•Êî∂ÂΩ±ÂÉèÂπÄ
                    if not frame_queue.full():
                        frame_queue.put_nowait(frame.to_ndarray(format="bgr24")) #Â∞áÂΩ±ÂÉèÂπÄËΩâÁÇ∫ numpy Èô£Âàó ‰∏¶ÊîæÂÖ•‰ΩáÂàó ÁÇ∫‰ªÄÈ∫ºË¶ÅÈÄôÈ∫ºÂÅö? Âõ†ÁÇ∫‰∏ªÁ∑öÁ®ãÊúÉÂæûÈÄôÂÄã‰ΩáÂàóÂèñÂá∫ÂΩ±ÂÉèÂπÄÈÄ≤Ë°åËôïÁêÜ
                except asyncio.TimeoutError:
                    print(f"[{path}] Êé•Êî∂ÂΩ±ÂÉèÂπÄË∂ÖÊôÇ„ÄÇ")
                    break
                except Exception: break


    try:
        # === STEP 1 Âª∫Á´ã WebRTC Offer ===
        url = f"{mediamtx_base_url}/{path}/whep" #WebRTC ÈÄ£Á∑ö URL #192.168.196.73:8889/cam0/whepÊàñcam1
        print(f"[{path}] Ê≠£Âú®ÈÄ£Êé•Âà∞ WebRTC: {url} ...")
        pc.addTransceiver("video", direction="recvonly") #Ê∑ªÂä†ÂΩ±ÂÉèÊé•Êî∂Âô® #direction="recvonly" Ë°®Á§∫Âè™Êé•Êî∂ÂΩ±ÂÉè
        offer = await pc.createOffer() #Âª∫Á´ã Offer SDP ÈÄôË£°Â∞±ÊòØÁ¨¨‰∫åÊ≠• ÂâçÈù¢Âª∫Á´ã RTCPeerConnection
        await pc.setLocalDescription(offer) #Ë®≠ÂÆöÊú¨Âú∞ÊèèËø∞ ÁÇ∫‰ªÄÈ∫ºË¶ÅË®≠ÂÆöÊú¨Âú∞ÊèèËø∞? Âõ†ÁÇ∫ÊàëÂÄëË¶ÅÊääÈÄôÂÄã Offer SDP ÁôºÈÄÅÁµ¶ mediamtx ‰º∫ÊúçÂô®



        # === STEP 2. ÂÇ≥ÈÄÅ SDP Áµ¶ MediaMTXÔºàWHEP APIÔºâ ===
        async with aiohttp.ClientSession() as session: #Âª∫Á´ãÈùûÂêåÊ≠• HTTP Session
            async with session.post(url, data=pc.localDescription.sdp, headers={"Content-Type": "application/sdp"}) as resp: #ÁôºÈÄÅ POST Ë´ãÊ±Ç ‰∫§Êèõ SDP
                if resp.status != 201: #Ê™¢Êü•ÂõûÊáâÁãÄÊÖãÁ¢º 201 Ë°®Á§∫ÊàêÂäüÂª∫Á´ã WebRTC ÈÄ£Á∑ö
                    print(f"[{path}] ÈÄ£Á∑öÂ§±ÊïóÔºåÁãÄÊÖãÁ¢º: {resp.status}")
                    return
                answer_sdp = await resp.text() #ÂèñÂæó Answer SDP
                await pc.setRemoteDescription(RTCSessionDescription(sdp=answer_sdp, type="answer")) #Ë®≠ÂÆöÈÅ†Á´ØÊèèËø∞ ÁÇ∫‰ªÄÈ∫ºË¶ÅË®≠ÂÆöÈÅ†Á´ØÊèèËø∞? Âõ†ÁÇ∫ÊàëÂÄëË¶ÅÂëäË®¥ RTCPeerConnection Â∞çÊñπÁöÑÈÄ£Á∑öÂèÉÊï∏
                print(f"[{path}] WebRTC ÈÄ£Á∑öÊàêÂäüÔºÅ")


        # === STEP 3. ÊåÅÁ∫å‰øùÊåÅÈÄ£Á∑ö ===
        while not shutdown_event.is_set():
            await asyncio.sleep(0.5)
    except asyncio.CancelledError: pass
    finally:
        await pc.close()
        print(f"[{path}] WebRTC ÈÄ£Á∑öÂ∑≤ÈóúÈñâ„ÄÇ")








#--- 2. WebRTC Êé•Êî∂Âü∑Ë°åÁ∑í --- ÈÄôÊòØËÉåÊôØÂü∑Ë°åÁ∑í Áî®ÊñºÊé•Êî∂ WebRTC ÂΩ±ÂÉè‰∏≤ÊµÅ Âõ†ÁÇ∫ WebRTC ÈúÄË¶ÅÈùûÂêåÊ≠•ËôïÁêÜ
#‰ªÄÈ∫ºÂè´ÈùûÂêåÊ≠•ËôïÁêÜÂë¢? Â∞±ÊòØË™™ÊàëÂÄë‰∏çÊúÉÈòªÂ°û‰∏ªÁ∑öÁ®ã Á≠âÂæÖÂΩ±ÂÉèÂπÄÁöÑÂà∞‰æÜ
#ËÄåÊòØ‰ΩøÁî® asyncio ‰∫ã‰ª∂Ëø¥Âúà‰æÜËôïÁêÜÂΩ±ÂÉèÂπÄÁöÑÊé•Êî∂     asyncioÊòØ Python ÁöÑÈùûÂêåÊ≠• I/O Ê°ÜÊû∂
#IO ÊåáÁöÑÊòØËº∏ÂÖ•Ëº∏Âá∫Êìç‰Ωú ‰æãÂ¶ÇÁ∂≤Ë∑ØË´ãÊ±Ç Ê™îÊ°àËÆÄÂØ´Á≠â
#ÈÄôÊ®£‰∏ªÁ∑öÁ®ãÂ∞±ÂèØ‰ª•ÁπºÁ∫åÂü∑Ë°åÂÖ∂‰ªñ‰ªªÂãô ÊØîÂ¶ÇÂΩ±ÂÉèËôïÁêÜËàáÈ°ØÁ§∫

#ÁÇ∫‰ªÄÈ∫ºË¶ÅÊúâÈÄôÂÄã ‰∏äÈù¢‰∏çÊòØÂ∞±ÊúâÈÄ£Á∑ö‰∫ÜÂóé?
#Á≠î: ÈÄôÂÄã webrtc_receiver_thread ÂáΩÂºèÊòØÂ∞ç‰∏äÈù¢ webrtc_receiver_task ÁöÑ‰∏ÄÂÄãÂ∞ÅË£ù
#ÂÆÉÂú®‰∏ÄÂÄãÁç®Á´ãÁöÑÂü∑Ë°åÁ∑í‰∏≠ÈÅãË°åÈùûÂêåÊ≠•ÁöÑ WebRTC Êé•Êî∂‰ªªÂãô
#ÈÄôÊ®£ÂèØ‰ª•ËÆì‰∏ªÁ∑öÁ®ãÂ∞àÊ≥®ÊñºÂΩ±ÂÉèËôïÁêÜËàáÈ°ØÁ§∫ ËÄå‰∏çÊúÉË¢´ WebRTC ÁöÑÈùûÂêåÊ≠•Êìç‰ΩúÈòªÂ°û


#Âú®ËÉåÊôØÂü∑Ë°åÁ∑í‰∏≠ÈÅãË°åÈùûÂêåÊ≠•ÁöÑ WebRTC Êé•Êî∂‰ªªÂãô
def webrtc_receiver_thread(path, frame_queue, shutdown_event):  #frame_queqeÊòØpathÂÖ©ÂÄãÈè°È†≠

    #WebRTC Êé•Êî∂Âü∑Ë°åÁ∑íÔºåÂåÖÂê´Ëá™ÂãïÈáçÈÄ£Ê©üÂà∂
    #Èáç‰ΩúÂêß...ÊáâË©≤ÁÆó


    # ÁÇ∫ÊØèÂÄãÂü∑Ë°åÁ∑íÂª∫Á´ã‰∏¶Ë®≠ÂÆöÁç®Á´ãÁöÑ asyncio ‰∫ã‰ª∂Ëø¥Âúà
    loop = asyncio.new_event_loop()  # Âú®ËÉåÊôØÂü∑Ë°åÈùûÂêåÊ≠•‰∫ã‰ª∂Ëø¥Âúà
    asyncio.set_event_loop(loop) #Ë®≠ÂÆöÁï∂ÂâçÂü∑Ë°åÁ∑íÁöÑ‰∫ã‰ª∂Ëø¥Âúà


    #Êé•ÂñÆÊµÅÁ®ã
    async def receiver_task(): #ÈùûÂêåÊ≠•Êé•Êî∂‰ªªÂãô
        while not shutdown_event.is_set():  # ÈÄôË£°ÊòØËá™ÂãïÈáçÈÄ£ÁöÑÈóúÈçµ  Áï∂0ÁöÑÊôÇÂÄô ÊåÅÁ∫åÂ∑•‰ΩúÁõ¥Âà∞ÈóúÈñÄ
            pc = None
            try:
                # Âª∫Á´ãÊñ∞ÈÄ£Á∑öÁöÑÁ®ãÂºèÁ¢º
                ice_servers = [
                    RTCIceServer(urls=["stun:stun.l.google.com:19302"]) #‰ΩøÁî® Google ÁöÑÂÖ¨ÂÖ± STUN ‰º∫ÊúçÂô® #ÂçîÂä© NAT Á©øË∂ä
                ]
                config = RTCConfiguration(iceServers=ice_servers) #Âª∫Á´ã RTC ÈÖçÁΩÆ

                # ÂïüÁî® RTCP ÂèçÈ•ãÊ©üÂà∂ÔºåËÆìÂÆ¢Êà∂Á´ØÂèØ‰ª•Ë´ãÊ±ÇÈóúÈçµÂπÄ (PLI/FIR)
                pc = RTCPeerConnection(configuration=config)
                pc.RTCP_REPORTS_DEFAULT = True  # Á¢∫‰øù RTCP Â†±ÂëäÊòØÂïüÁî®ÁöÑ

                # ‰ΩøÁî®‰∏ÄÂÄãÈùûÂêåÊ≠•ÁöÑ Queue ‰æÜÊ®ôË®ò on_track ÊòØÂê¶ÊàêÂäüÊé•Êî∂Âà∞Á¨¨‰∏ÄÂπÄ
                first_frame_received = asyncio.Queue(maxsize=1)


                #Êî∂Âà∞ÂΩ±ÂÉèË¶ÅÂÅöÁîöÈ∫º?
                @pc.on("track")
                async def on_track(track):
                    print(f"[{path}] Êé•Êî∂Âà∞ Track: {track.kind}") #ÂàóÂç∞Êé•Êî∂Âà∞ÁöÑ Track È°ûÂûã
                    if track.kind == "video":
                        try:
                            # ÂòóË©¶Êé•Êî∂Á¨¨‰∏ÄÂπÄÔºåË®≠ÂÆöËºÉÈï∑ÁöÑÈÄæÊôÇ
                            first_frame = await asyncio.wait_for(track.recv(), timeout=15.0) #Êé•Êî∂‰∏ÄÂπÄÂΩ±ÂÉè
                            print(f"[{path}] ‚úÖ ÊàêÂäüÊé•Êî∂Âà∞Á¨¨‰∏ÄÂÄãÊúâÊïàÂΩ±ÂÉèÂπÄÔºÅ")
                            #ÊääÁ¨¨‰∏ÄÂπÄÂΩ±ÂÉèÊîæÈÄ≤‰ΩáÂàó
                            if not frame_queue.full():
                                frame_queue.put_nowait(first_frame.to_ndarray(format="bgr24"))
                            # ÈÄöÁü•‰∏ªËø¥ÂúàÁ¨¨‰∏ÄÂπÄÂ∑≤Êî∂Âà∞
                            await first_frame_received.put(True)

                            # ÁπºÁ∫åÊé•Êî∂ÂæåÁ∫åÁöÑÂπÄ
                            while not shutdown_event.is_set():
                                frame = await asyncio.wait_for(track.recv(), timeout=5.0)
                                if not frame_queue.full():
                                    frame_queue.put_nowait(frame.to_ndarray(format="bgr24"))
                        except asyncio.TimeoutError:
                            print(f"[{path}] ‚ö†Ô∏è Êé•Êî∂ÂΩ±ÂÉèÂπÄË∂ÖÊôÇÔºåÂ∞áÂòóË©¶ÈáçÊñ∞ÈÄ£Á∑ö„ÄÇ")
                        except Exception as e:
                            print(f"[{path}] ‚ö†Ô∏è Track Êé•Êî∂ÊôÇÁôºÁîüÈåØË™§: {e}ÔºåÂ∞áÂòóË©¶ÈáçÊñ∞ÈÄ£Á∑ö„ÄÇ")
                        finally:
                            # Â¶ÇÊûú on_track Ëø¥Âúà‰∏≠Êñ∑ÔºåÁ¢∫‰øù first_frame_received ‰ΩáÂàóÊúâÊù±Ë•ø
                            # ‰ª•ÂÖçÂ§ñÂ±§ÁöÑ await first_frame_received.get() Âç°Ê≠ª
                            if first_frame_received.empty():
                                await first_frame_received.put(False)

                # --- ÈÄ£Á∑öÊµÅÁ®ã ---
                #Âª∫Á´ãwebrtc ÈÄ£Á∑ö(ÈñãÈñÄÁáüÊ•≠)
                url = f"{mediamtx_base_url}/{path}/whep" #WebRTC ÈÄ£Á∑ö URL
                print(f"[{path}] Ê≠£Âú®ÂòóË©¶ÈÄ£Êé•Âà∞ WebRTC: {url} ...")
                pc.addTransceiver("video", direction="recvonly") #Âè™Êé•Êî∂ÂΩ±ÂÉè
                offer = await pc.createOffer() #Âª∫Á´ã Offer SDP
                await pc.setLocalDescription(offer) #Ë®≠ÂÆöÊú¨Âú∞ÊèèËø∞

                #Ëàá‰º∫ÊúçÂô®‰∫§ÊèõÈÄ£Á∑öË≥áË®ä(Á¢∫Ë™çË®ÇÂñÆ)
                async with aiohttp.ClientSession() as session: #Âª∫Á´ãÈùûÂêåÊ≠• HTTP Session
                    async with session.post(url, data=pc.localDescription.sdp, #ÁôºÈÄÅ Offer SDP  ÈÄôÊôÇÂÄô mediamtx ‰º∫ÊúçÂô®ÊúÉÂõûÂÇ≥ Answer SDP Â¶ÇÊûúÂèØ‰ª•Â∞±ÊúÉÂÇ≥track
                                            headers={"Content-Type": "application/sdp"}) as resp:
                        if resp.status != 201:
                            print(f"[{path}] ‚ùå ÈÄ£Á∑öÂ§±ÊïóÔºåÁãÄÊÖãÁ¢º: {resp.status}„ÄÇÂ∞áÂú® 5 ÁßíÂæåÈáçË©¶„ÄÇ")
                            await asyncio.sleep(5)
                            continue  # Ë∑≥Âà∞‰∏ã‰∏ÄÊ¨° while Ëø¥Âúà

                        answer_sdp = await resp.text() #ÂèñÂæó Answer SDP(SDP ÂåÖÂê´ Á∑®Ëß£Á¢ºÂô® Á∂≤Ë∑Ø‰ΩçÂùÄÁ≠âË≥áË®ä)


                        # ‰ΩøÁî® RTCSessionDescription ‰æÜÂ∞ÅË£ù SDPÔºåËÄå‰∏çÊòØ‰∏çÂ≠òÂú®ÁöÑ parse_sdp
                        remote_description = RTCSessionDescription(sdp=answer_sdp, type="answer") #Âª∫Á´ãÈÅ†Á´ØÊèèËø∞
                        await pc.setRemoteDescription(remote_description) #Ë®≠ÂÆöÈÅ†Á´ØÊèèËø∞

                        print(f"[{path}] ‚úÖ WebRTC SDP ‰∫§ÊèõÊàêÂäüÔºÅÁ≠âÂæÖÁ¨¨‰∏ÄÂÄãÂΩ±ÂÉèÂπÄ...")

                # Á≠âÂæÖ on_track ÊàêÂäüÊé•Êî∂Âà∞Á¨¨‰∏ÄÂπÄÔºåÊàñÈÄæÊôÇ
                try:
                    success = await asyncio.wait_for(first_frame_received.get(), timeout=15.0)
                    if not success:
                        print(f"[{path}] ‚ö†Ô∏è on_track ÂõûÂëº‰∏≠ÁôºÁîüÈåØË™§ÔºåÊ∫ñÂÇôÈáçÈÄ£„ÄÇ")
                        continue
                except asyncio.TimeoutError:
                    print(f"[{path}] ‚ùå Á≠âÂæÖÁ¨¨‰∏ÄÂÄãÂΩ±ÂÉèÂπÄÈÄæÊôÇ (15s)ÔºåÂ∞áÂòóË©¶ÈáçÊñ∞ÈÄ£Á∑ö„ÄÇ")
                    continue

                # Â¶ÇÊûúÈÄ£Á∑öÊàêÂäü‰∏îÊî∂Âà∞ÂπÄÔºåÂ∞±‰øùÊåÅÈÄ£Á∑öÁãÄÊÖã
                print(f"[{path}] ÈÄ£Á∑öÁ©©ÂÆöÔºåÈÄ≤ÂÖ•Áõ£ÊéßÁãÄÊÖã...")
                while not shutdown_event.is_set() and pc.connectionState in ["connected", "connecting"]:
                    await asyncio.sleep(1)
                print(f"[{path}] ÈÄ£Á∑öÁãÄÊÖãËÆäÁÇ∫ {pc.connectionState}ÔºåÊ∫ñÂÇôÈáçÈÄ£„ÄÇ")

            except asyncio.CancelledError:
                print(f"[{path}] Êé•Êî∂‰ªªÂãôË¢´ÂèñÊ∂à„ÄÇ")
                break  # ÈÄÄÂá∫ while Ëø¥Âúà
            except Exception as e:
                print(f"[{path}] ‚ùå ÁôºÁîüÊú™È†êÊúüÁöÑÂö¥ÈáçÈåØË™§: {e}")
                traceback.print_exc()
            finally:
                if pc:
                    await pc.close()
                if not shutdown_event.is_set():
                    print(f"[{path}] ÈÄ£Á∑öÂ∑≤ÈóúÈñâÔºåÂ∞áÂú® 5 ÁßíÂæåËá™ÂãïÈáçÊñ∞ÈÄ£Á∑ö...")
                    await asyncio.sleep(5)

    loop.run_until_complete(receiver_task())



def webcam_receiver_thread(camera_index, frame_queue, shutdown_event): #Êú¨Âú∞ÊîùÂÉèÈ†≠Êé•Êî∂Âü∑Ë°åÁ∑í
    print(f"üé• Ê≠£Âú®ÂïüÂãïÊú¨Âú∞ÊîùÂÉèÈ†≠ #{camera_index} ...") #ÂàóÂç∞ÂïüÂãïË®äÊÅØ
    cap = cv2.VideoCapture(camera_index) #ÈñãÂïüÊú¨Âú∞ÊîùÂÉèÈ†≠
    if not cap.isOpened(): #Ê™¢Êü•ÊòØÂê¶ÊàêÂäüÈñãÂïüÊîùÂÉèÈ†≠
        print(f"ÈåØË™§ÔºöÁÑ°Ê≥ïÈñãÂïüÊîùÂÉèÈ†≠ #{camera_index}")
        return
    while not shutdown_event.is_set():
        ret, frame = cap.read()
        if not ret:
            print(f"‚ö†Ô∏è ÁÑ°Ê≥ïÂæûÊîùÂÉèÈ†≠ #{camera_index} ËÆÄÂèñÂΩ±ÂÉèÂπÄ„ÄÇ")
            break
        if not frame_queue.full():
            frame_queue.put_nowait(frame)
        time.sleep(0.01)
    cap.release()
    print(f"üì∑ ÊîùÂÉèÈ†≠Âü∑Ë°åÁ∑í #{camera_index} Â∑≤ÁµêÊùü„ÄÇ")



# --- 3. ‰∏ªÁ®ãÂºè ---
def main():
    trip_id = f"trip_{uuid.uuid4().hex[:8]}"
    print(f"====== Êú¨Ê¨°Ë°åÁ®ã ID: {trip_id} ======")
    notify_backend(RECORDING_STATUS_ENDPOINT, {"session_id": trip_id, "status": "start"})

    shutdown_event = threading.Event() #ÁµêÊùüÈÄöÁü•

    #1.Ê∫ñÂÇôÂ∑•‰Ωú
    frame_queues, receiver_threads = {}, [] #Á∑©Ë°ùÂçÄ


    if INPUT_SOURCE_MODE == "WEBRTC":
        active_paths = stream_paths
        print(f"--- ÂïüÂãï WebRTC Ê®°ÂºèÔºåËôïÁêÜ‰∏≤ÊµÅ: {active_paths} ---")
        for path in active_paths:
            frame_queues[path] = Queue(maxsize=5)
            #ÂèØ‰ª•Áõ¥Êé•ÂëºÂè´

            #Ë´ã‰∏ÄÂÄãÊúçÂãôÁîü(ÂïüÂãïWebrtcÂü∑Ë°åÁ∑í)
            thread = threading.Thread(target=webrtc_receiver_thread, args=(path, frame_queues[path], shutdown_event), daemon=True)
            receiver_threads.append(thread); thread.start()
    elif INPUT_SOURCE_MODE == "WEBCAM":
        active_paths = [f"webcam{i}" for i in local_camera_indices]
        print(f"--- ÂïüÂãïÊú¨Âú∞ Webcam Ê®°ÂºèÔºåËôïÁêÜÈè°È†≠: {local_camera_indices} ---")
        for i, path in zip(local_camera_indices, active_paths):
            frame_queues[path] = Queue(maxsize=5)
            thread = threading.Thread(target=webcam_receiver_thread, args=(i, frame_queues[path], shutdown_event), daemon=True)
            receiver_threads.append(thread); thread.start()
    else:
        print(f"ÈåØË™§ÔºöÊú™Áü•ÁöÑ INPUT_SOURCE_MODE: {INPUT_SOURCE_MODE}"); return




    print("--- Ê≠£Âú®ËºâÂÖ•ÊâÄÊúâ AI Ê®°Âûã... ---")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    yolo_model = YOLO(YOLO_MODEL_PATH)
    with open(YNET_CONFIG_PATH, 'r', encoding='utf-8') as file:
        params = yaml.load(file, Loader=yaml.FullLoader)
    obs_len = params['obs_len']
    ynet_model = YNet(obs_len=obs_len, pred_len=params['pred_len'], params=params)
    ynet_model.load(YNET_MODEL_PATH)
    ynet_model.model.to(device).eval()
    checkpoint = torch.load(SEG_MODEL_PATH, map_location=device)
    seg_model = modeling.deeplabv3plus_mobilenet(num_classes=19, output_stride=16)
    seg_model.load_state_dict({k.replace('module.',''):v for k,v in checkpoint['model_state'].items()})
    seg_model.to(device).eval()
    tracker = ByteTrack()
    input_template = torch.Tensor(create_dist_mat(size=2000)).to(device)
    print("--- ÊâÄÊúâÊ®°ÂûãËºâÂÖ•ÂÆåÊàêÔºÅ ---")




    all_track_histories = {path: defaultdict(lambda: deque(maxlen=obs_len)) for path in active_paths}
    all_track_predictions = {path: {} for path in active_paths}
    all_frame_idx = {path: 0 for path in active_paths}
    all_cached_seg_maps = {path: None for path in active_paths}
    last_danger_notify_time = {path: 0 for path in active_paths}
    video_writers = {}

    print("\n--- Á≠âÂæÖÊâÄÊúâÂΩ±ÂÉè‰æÜÊ∫êÁöÑÁ¨¨‰∏ÄÂπÄÔºåÊúÄÂ§öÁ≠âÂæÖ 30 Áßí... ---")
    initial_frames = {}
    time.sleep(2)
    for path in active_paths:
        try:
            print(f"Ê≠£Âú®Á≠âÂæÖ [{path}] ÁöÑÁ¨¨‰∏ÄÂπÄ...")
            frame = frame_queues[path].get(timeout=30)
            initial_frames[path] = frame
            print(f"‚úÖ ÊàêÂäüÊé•Êî∂Âà∞ [{path}] ÁöÑÁ¨¨‰∏ÄÂπÄÔºÅ")
        except Empty:
            print(f"‚ùå Ë≠¶ÂëäÔºöÁ≠âÂæÖ [{path}] ÁöÑÁ¨¨‰∏ÄÂπÄË∂ÖÊôÇÔºåÂ∞áÂøΩÁï•Ê≠§‰∏≤ÊµÅ„ÄÇ")

    active_paths = list(initial_frames.keys())
    if not active_paths:
        print("ÈåØË™§ÔºöÊ≤íÊúâ‰ªª‰ΩïÂΩ±ÂÉè‰æÜÊ∫êÊàêÂäüÈÄ£Êé•„ÄÇÁ®ãÂºèÂç≥Â∞áÈÄÄÂá∫„ÄÇ")
        shutdown_event.set()

    try:
        while not shutdown_event.is_set():
            for path in active_paths:
                if path in initial_frames:
                    frame_orig = initial_frames.pop(path)
                else:
                    try:
                        frame_orig = frame_queues[path].get_nowait()  #ÂæûÁ∑©Ë°ùÂçÄÊãøË®ÇÂñÆ
                    except Empty:
                        continue

                window_name = f"Intelligent Recorder - {path}"
                track_histories = all_track_histories[path]
                track_predictions = all_track_predictions[path]
                frame_idx = all_frame_idx[path]
                cached_seg_map = all_cached_seg_maps[path]

                if path not in video_writers and SAVE_VIDEO:
                    height, width, _ = frame_orig.shape
                    save_path = os.path.join(RECORD_OUTPUT_DIR, f"{path}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4")
                    video_writers[path] = {'writer': VideoWriterThread(save_path, (width, height)), 'start_time': time.time(), 'path': save_path, 'danger_zone': np.array([[int(width*0.25), int(height*0.6)], [int(width*0.75), int(height*0.6)], [int(width*0.95), height-1], [int(width*0.05), height-1]], np.int32)}
                    video_writers[path]['writer'].start()

                canvas = frame_orig.copy()
                all_frame_idx[path] += 1
                frame_model_size = cv2.resize(frame_orig, (MODEL_INPUT_WIDTH, MODEL_INPUT_HEIGHT))

                results = yolo_model(frame_model_size, verbose=False, classes=CLASSES_TO_TRACK)
                detections = results[0].boxes.data.cpu().numpy()
                tracked_objects = tracker.update(detections, frame_model_size)
                active_track_ids = {int(obj[4]) for obj in tracked_objects}
                track_predictions = {tid: pred for tid, pred in track_predictions.items() if tid in active_track_ids}

                if frame_idx % SEGMENTATION_INTERVAL == 0 or cached_seg_map is None:
                    img_rgb = cv2.cvtColor(frame_model_size, cv2.COLOR_BGR2RGB)
                    img_tensor = torch.from_numpy(img_rgb.astype(np.float32)/255.0).permute(2,0,1)
                    mean, std = torch.tensor([0.485,0.456,0.406],device=device).view(3,1,1), torch.tensor([0.229,0.224,0.225],device=device).view(3,1,1)
                    seg_input_tensor = ((img_tensor.to(device) - mean)/std).unsqueeze(0)
                    with torch.no_grad():
                        seg_logits = seg_model(seg_input_tensor)
                        if isinstance(seg_logits, dict): seg_logits = seg_logits['out']
                        cached_seg_map = torch.argmax(seg_logits.squeeze(), dim=0).cpu().numpy()
                    all_cached_seg_maps[path] = cached_seg_map

                tracks_to_predict = []
                for obj in tracked_objects:
                    x1, y1, x2, y2, track_id = obj[:5]
                    track_histories[int(track_id)].append([(x1+x2)/2, y2])
                    if len(track_histories[int(track_id)]) == obs_len:
                        tracks_to_predict.append(int(track_id))

                if tracks_to_predict:
                    with torch.no_grad():
                        num_to_predict = len(tracks_to_predict)
                        batch_hist = torch.from_numpy(np.array([list(track_histories[tid]) for tid in tracks_to_predict])).float().to(device)
                        vel = batch_hist[:, 1:] - batch_hist[:, :-1]
                        obs_vel = torch.cat([torch.zeros((num_to_predict, 1, 2), device=device), vel], dim=1)
                        acc = obs_vel[:, 1:] - obs_vel[:, :-1]
                        obs_acc = torch.cat([torch.zeros((num_to_predict, 1, 2), device=device), acc], dim=1)
                        h_ynet, w_ynet = MODEL_INPUT_HEIGHT, MODEL_INPUT_WIDTH
                        seg_map_onehot = F.one_hot(torch.from_numpy(cached_seg_map).long().to(device), 19)
                        seg_map_batch = seg_map_onehot.permute(2,0,1).float().unsqueeze(0).repeat(num_to_predict,1,1,1)
                        vel_map = torch.stack([torch.stack([create_arrow_heatmap(h_ynet,w_ynet,c[0],c[1],v[0],v[1],device=device) for c,v in zip(batch_hist[:,i,:],obs_vel[:,i,:])]) for i in range(obs_len)], dim=1)
                        acc_map = torch.stack([torch.stack([create_arrow_heatmap(h_ynet,w_ynet,c[0],c[1],a[0],a[1],device=device) for c,a in zip(batch_hist[:,i,:],obs_acc[:,i,:])]) for i in range(obs_len)], dim=1)
                        features = ynet_model.model.pred_features(torch.cat([seg_map_batch, vel_map, acc_map], dim=1))
                        pred_waypoint = ynet_model.model.pred_goal(features)[:, params['waypoints']]
                        pred_waypoint_sm = ynet_model.model.sigmoid(pred_waypoint / params['temperature'])
                        goal_samples = sampling(pred_waypoint_sm[:,-1:], num_samples=params.get('num_goals',20)).permute(2,0,1,3)
                        goal_scores = torch.stack([torch.stack([pred_waypoint_sm[i,-1,torch.clamp(g[i,0,1].long(),0,h_ynet-1),torch.clamp(g[i,0,0].long(),0,w_ynet-1)] for i in range(num_to_predict)]) for g in goal_samples])
                        future_samples = []
                        for waypoint in goal_samples:
                            waypoint_map = get_patch(input_template, waypoint.reshape(-1,2).cpu().numpy(), h_ynet, w_ynet).reshape([-1,1,h_ynet,w_ynet])
                            traj_input = [torch.cat([feat, F.interpolate(waypoint_map, size=feat.shape[2:], mode='bilinear', align_corners=False)], dim=1) for feat in features]
                            future_samples.append(ynet_model.model.softargmax(ynet_model.model.pred_traj(traj_input)))
                        future_samples = torch.stack(future_samples)
                        best_indices = torch.argmax(goal_scores, dim=0)
                        best_future = future_samples.permute(1,0,2,3)[torch.arange(num_to_predict), best_indices]
                        for i, track_id in enumerate(tracks_to_predict):
                            track_predictions[track_id] = best_future[i].cpu().numpy()

                orig_h, orig_w = frame_orig.shape[:2]
                w_scale, h_scale = orig_w/MODEL_INPUT_WIDTH, orig_h/MODEL_INPUT_HEIGHT

                danger_zone_poly = video_writers.get(path, {}).get('danger_zone')
                is_danger = False
                if danger_zone_poly is not None:
                    is_danger = any(cv2.pointPolygonTest(danger_zone_poly, (int(p[0]), int(p[1])), False) >= 0 for tid in track_predictions for p in (track_predictions[tid] * [w_scale, h_scale]))

                    if is_danger and (time.time() - last_danger_notify_time[path] > 10):
                        # 1. Êõ¥Êñ∞ÊôÇÈñìÔºåÁ≠âÊñºÈÄ≤ÂÖ•‚ÄúÂÜ∑ÂçªÂÄíÊï∏‚Äù
                        last_danger_notify_time[path] = time.time()

                        # 2. Ê∫ñÂÇôÊï∏Êìö‰∏¶ÁôºÈÄÅÈÄöÁü•
                        print(f"[{path}] ÂÅµÊ∏¨Âà∞Âç±Èö™ÔºÅÁôºÈÄÅÈÄöÁü•‰∏¶ÂÜ∑Âçª 10 Áßí„ÄÇ")
                        danger_data = {
                            "trip_id": trip_id,
                            "event_type": "ËªåË∑°È†êÊ∏¨Ë≠¶Âëä",
                            "description": f"Èè°È†≠ [{path}] ÂÅµÊ∏¨Âà∞ÊúâÁâ©È´îËªåË∑°ÈÄ≤ÂÖ•Âç±Èö™ÂçÄÂüüÔºÅ"
                        }
                        threading.Thread(target=notify_backend, args=(NOTIFY_DANGER_ENDPOINT, danger_data)).start()


                    zone_color = (0,0,255) if is_danger else (0,255,0)
                    cv2.polylines(canvas, [danger_zone_poly], True, zone_color, 3)
                    # if is_danger:
                    #     text = "!!! WARNING !!!"
                    #     text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_TRIPLEX, 2, 3)
                    #     cv2.putText(canvas, text, ((orig_w-text_size[0])//2, int(orig_h*0.2)), cv2.FONT_HERSHEY_TRIPLEX, 2, (0,0,255), 3)

                for obj in tracked_objects:
                    x1,y1,x2,y2,tid = [int(p) for p in obj[:5]]
                    x1_o,y1_o,x2_o,y2_o = int(x1*w_scale),int(y1*h_scale),int(x2*w_scale),int(y2*h_scale)
                    cv2.rectangle(canvas, (x1_o,y1_o), (x2_o,y2_o), (0,255,0), 2)
                    cv2.putText(canvas, f"ID:{tid}", (x1_o,y1_o-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)

                    obs_orig_defined = False
                    if tid in track_histories and len(track_histories[tid]) > 1:
                        obs_orig = (np.array(track_histories[tid]) * [w_scale,h_scale]).astype(np.int32)
                        obs_orig_defined = True
                        for k in range(len(obs_orig)-1):
                            cv2.line(canvas, tuple(obs_orig[k]), tuple(obs_orig[k+1]), (255,100,0), 2)
                    if tid in track_predictions and obs_orig_defined:
                        pred_orig = (track_predictions[tid] * [w_scale,h_scale]).astype(int)
                        full_pred = np.vstack([obs_orig[-1], pred_orig])
                        for k in range(len(full_pred)-1):
                            cv2.line(canvas, tuple(full_pred[k]), tuple(full_pred[k+1]), (0,0,255), 2)
                #‰∏äËèú(È°ØÁ§∫ÁµêÊûú)
                cv2.imshow(window_name, canvas)
                if path in video_writers:
                    video_writers[path]['writer'].add_frame_to_queue(canvas)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                shutdown_event.set()
                break
    finally:
        print(f"====== Ë°åÁ®ã {trip_id} Â∑≤ÁµêÊùü ======")
        shutdown_event.set()
        for thread in receiver_threads:
            thread.join(timeout=2)
        for path in video_writers:
            vw_data = video_writers[path]
            vw_data['writer'].stop()
            vw_data['writer'].join()
            video_filename = os.path.basename(vw_data['path'])
            relative_path = os.path.join(VIDEO_FILES_DIR, video_filename).replace("\\","/")
            upload_data = { "trip_id": trip_id, "path": path, "relative_path": relative_path, "title": f"PiCamÈåÑÂΩ± - {path}", "date": datetime.now().strftime('%m/%d'), "description": f"ÊôÇÈï∑Á¥Ñ {round(time.time() - vw_data['start_time'])} Áßí„ÄÇ", }
            notify_backend(UPLOAD_VIDEO_ENDPOINT, upload_data)
        notify_backend(RECORDING_STATUS_ENDPOINT, {"session_id": trip_id, "status": "end"})
        cv2.destroyAllWindows()
        print("Á®ãÂºèÂ∑≤ÁµêÊùü„ÄÇ")

if __name__ == "__main__":
    main()